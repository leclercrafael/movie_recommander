{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdd51758",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "75ada24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports success\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "import warnings\n",
    "import math\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "print('Imports success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "12e193f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of CountVectorizer\n",
    "\n",
    "def myCountVectorizer (a : list) -> list :\n",
    "    '''\n",
    "    Returns the frequency of each word in each strings\n",
    "\n",
    "    Args :\n",
    "    a : a list of strings \n",
    "\n",
    "    Returns : \n",
    "    A list of list containing the frequency for each words\n",
    "    '''\n",
    "\n",
    "    out = [] #container of other lists\n",
    "\n",
    "    #We first need to determine the number of different words to make our index\n",
    "\n",
    "    def create_index(a : list) -> list :\n",
    "        '''\n",
    "        Returns the list of each word constituting an index\n",
    "\n",
    "        Args :\n",
    "        a : the same list of strings \n",
    "\n",
    "        Returns : \n",
    "        The list of all words present in all of our strings\n",
    "        '''\n",
    "\n",
    "        concatenation = ''\n",
    "\n",
    "        for indice, i in enumerate(a) :\n",
    "            if indice != (len(a)-1) : \n",
    "                concatenation += (i + ' ')\n",
    "            else:\n",
    "                concatenation += i\n",
    "\n",
    "        index = list(set(concatenation.split(' ')))\n",
    "\n",
    "        return index\n",
    "    \n",
    "    all_words = create_index(a=a)\n",
    "\n",
    "    for i in a :\n",
    "        sub_out = [0] * len(all_words)\n",
    "        words = i.split(' ')\n",
    "        for j in words:\n",
    "            sub_out[all_words.index(j)] +=1\n",
    "\n",
    "        out.append(sub_out)\n",
    "\n",
    "    \n",
    "    return (out, all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6ceaeb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([[1, 2, 1, 2], [1, 1, 2, 0]], ['Sofia', 'Paris', 'London', 'Berlin'])\n",
      "([[2, 1, 1, 1, 1], [1, 1, 2, 0, 0]], ['Paris', 'Sofia', 'London', 'Helsinki', 'Berlin'])\n",
      "[[1, 2, 1, 2], [1, 1, 2, 0]]\n"
     ]
    }
   ],
   "source": [
    "#Test of my implementation of CountVectorizer\n",
    "\n",
    "print(myCountVectorizer(['Berlin Paris London Paris Berlin Sofia', 'London Paris London Sofia'])) \n",
    "print(myCountVectorizer(['Helsinki Paris London Paris Berlin Sofia', 'London Paris London Sofia']))\n",
    "print(myCountVectorizer(['Berlin Paris London Paris Berlin Sofia', 'London Paris London Sofia'])[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "71350e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementation of cosinus similarity\n",
    "\n",
    "def mycosinussimilarity(b : list) -> list :\n",
    "\n",
    "    '''\n",
    "    Returns the cosinus similarity between each vector under the form of a matrix\n",
    "\n",
    "    Args : \n",
    "    b : list containing the CountVectorizer of our strings\n",
    "\n",
    "    Returns :\n",
    "    The matrix of similarity\n",
    "    \n",
    "    '''\n",
    "\n",
    "    out = [[1.]*len(b) for i in range(len(b))]  # Creation of the matrix\n",
    "\n",
    "    def produit_scalaire(x : list, y : list) -> float :\n",
    "        \n",
    "        '''\n",
    "        Returns the scalar product of the two input vectors\n",
    "\n",
    "        Args:\n",
    "        x, y : two vectors\n",
    "        '''\n",
    "\n",
    "        if len(x) != len(y) :\n",
    "            warnings.warn(\"The two inputs don't have the same dimensions.\", UserWarning)\n",
    "            return None\n",
    "        else:\n",
    "            sum = 0\n",
    "            for i in range(len(x)):\n",
    "                sum += (x[i]*y[i])\n",
    "\n",
    "        return sum\n",
    "    \n",
    "    def norm(x : list) -> float :\n",
    "\n",
    "        '''\n",
    "        Returns the norm of the input vector\n",
    "\n",
    "        Args:\n",
    "        x : vector\n",
    "        '''\n",
    "        out = 0\n",
    "        for i in x:\n",
    "            out += i**2\n",
    "\n",
    "        return math.sqrt(out)\n",
    "    \n",
    "    def cosinus(x : list, y : list) -> float :\n",
    "\n",
    "        return produit_scalaire(x,y)/(norm(x)*norm(y))\n",
    "    \n",
    "    '''We can start to fill the output : matrix of cosinus similarity. \n",
    "    This matrix being symetrical we do not have to compute every element, including the diagonal and one side of the matrix'''\n",
    "\n",
    "    for i in range(0, len(b)-1):\n",
    "        for j in range(i+1, len(b)):\n",
    "            out[i][j] = cosinus(b[i], b[j])\n",
    "            out[j][i] = cosinus(b[i], b[j])\n",
    "\n",
    "    return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
